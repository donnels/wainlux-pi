= k6 (MVP)

Short. Small. Useful.

Purpose::
* Replace `k6_burn_image.py` with a clean, testable library and a tiny CLI.
* Remove duplicate logic and temporary shims; hard cutover when parity is verified.
* **Based on:** the K6 protocol described in the documentation (see `documentation/reference-k6_protocol.adoc`).

Approach::
* Write the library cleanly: small modules, pure functions, well-documented public API.
* Test first: unit tests for pure code, mock transport for protocol tests, integration parity tests against the legacy script.
* Keep runtime behavior identical where it matters (protocol framing, ACKs, status parsing, CSV format).

Use cases & requirements::
* Burn a raster image with configurable power and depth and produce CSV+JSON logs that match the legacy format.
* Burn vector-only jobs (circle points) and patterns (boundary, circle).
* Support `--no-burn` upload-only mode for timing analysis.
* Support replaying burns from a saved JSON config file.
* Stream raster payloads in chunks to avoid large memory use (DATA_CHUNK≈1900) and implement retry/backoff on no-ACK.
* Parse device status frames (FF FF 00 XX) and heartbeat frames (FF FF FF FE) and report progress (0–100%).
* Expose robust, testable SerialTransport abstraction with a `MockTransport` for unit tests.
* Preserve or document current defaults: `mm_per_px=0.05`, `max_width≈1600px`, `ACK=0x09`, `retry_limit=5`, `wait_per_line` and `min_wait` behavior.
* Provide deterministic filenames: `stat-YY-MM-DD-HH-MM(.csv/.json/.png)` and write error logs.
* Keep memory and CPU footprint small (Pi Zero). Stream data, do not allocate full payloads.

What's here::
* `driver.py` : new canonical driver (initially a direct rewrite of behavior; soon to use `transport.py`).
* `processing.py` : image math helpers (mm/px, sizing, margins).
* `logger.py` : config and image save helpers; will grow into CSV logger.
* `cli.py` : thin, minimal CLI for local testing.

Next steps (now)::
* Implement `transport.py` (SerialTransport + MockTransport) and unit tests.
* Port protocol functions (send_cmd, checksum, job header, payload builder, wait_for_completion) into library modules with tests.
* Add parity tests that run the same inputs through old script and new library and diff the CSV/JSON outputs.
* **Interface plan:** provide a tiny CLI first for reliability and testing, then expose the library via a web API for the UI and automation.
* Once parity is proven, switch CLI and web API to use the new library and archive `k6_burn_image.py`.
* Add CI (pytest) and small hardware integration job (optional, gated).

Dev: Virtualenv & packaging (idiot-proof)::
* Create a project venv and install the script deps (runs from repo root):

[source,bash]
----
# from repo root
bash scripts/setup_venv.sh
source scripts/venv/bin/activate
pip install --upgrade pip
# optional: install pre-commit hooks
pip install pre-commit ruff black
pre-commit install --install-hooks || true
# run quick tests
python3 scripts/run_unit_tests.py
# run full test suite (if you have pytest installed)
python3 -m pytest -q || true
----

.Packaging notes (for Docker/Pi Zero):
  * We will containerize the library later. For now, the Docker context is in `docker-wainlux/docker`.
  * To build on the Pi Zero, the Pi needs at least 1GB swap. See `docker-wainlux/README.adoc` for build hints.
  * Use `docker compose build` and `docker compose up -d` from `/docker-wainlux` to run the service.

.Tear-down and rebuild mantra (Hemingway):
  * Stop containers. Remove venv. Rebuild clean. Test quick. Repeat. Do not hoard state.
  * If something fails, the reproducer should be a short shell script that recreates the failure from scratch.

.Design principles:
* KISS. DRY. Minimal public surface. Test first.

.Priorities:
* Clean, human-readable code: short sentences, clear names, no unnecessary comment prose (Hemingway-style).
* No magic: explicit behavior, no hidden side-effects, predictable interfaces.
* Simple beats complex; easy beats fancy.
* Small, reviewed changes; perfect is the enemy of good.
* Keep functions tiny and testable; avoid global state and surprises.

Code style checklist (Hemingway):
* Keep it short: one idea per function; aim for 10–30 lines.
* Name plainly: nouns for classes, verbs for functions, no abbreviations.
* No magic numbers: name constants and explain why.
* Pure logic separate from side effects; side effects live in thin adapters.
* No global state: pass inputs, return outputs.
* Short docstrings: one-line summary, inputs, outputs.
* Tests for behavior, not implementation.
* Readability > cleverness.

Enforcement (light):
* Use `pre-commit` with `ruff` (lint) and `black` (format) to catch basic issues.
* Keep changes small and reviewed; use the checklist during code review.

Usage::
[source,bash]
----
# Draw boundary using the wrapper
scripts/k6/cli.py bounds --mm 75 --depth 5

# Engrave an image (calls existing script under the hood)
scripts/k6/cli.py engrave wifi.png --power 1000 --depth 10
----

== CSV Logging (NEW)

The new library includes built-in CSV logging that matches the legacy script format.

=== Quick Start

[source,python]
----
from scripts.k6.driver import WainluxK6
from scripts.k6.transport import SerialTransport
from scripts.k6.csv_logger import CSVLogger

driver = WainluxK6()
transport = SerialTransport("/dev/ttyUSB0", baudrate=115200)

# Use context manager for automatic file close
with CSVLogger("burn_log.csv") as logger:
    driver.connect_transport(transport, csv_logger=logger)
    result = driver.engrave_transport(
        transport, "image.png", 
        power=1000, depth=100,
        csv_logger=logger
    )
----

=== CSV Format

Each row captures timing, throughput, and retry metrics:

----
burn_start,timestamp,elapsed_s,phase,operation,duration_ms,
bytes_transferred,cumulative_bytes,throughput_kbps,status_pct,
state,response_type,retry_count,device_state
----

=== Logged Operations

* *Connect phase:* VERSION, CONNECT #1, CONNECT #2, HOME
* *Setup phase:* FRAMING, JOB_HEADER, pre-burn CONNECT
* *Burn phase:* DATA chunks (one row per chunk, retries logged separately)
* *Finalize phase:* INIT #1, INIT #2
* *Wait phase:* STATUS updates (progress 0–100%)

=== Example CSV Output

[%header]
,====
burn_start,timestamp,elapsed_s,phase,operation,duration_ms,bytes_transferred,cumulative_bytes,throughput_kbps,status_pct,state,response_type,retry_count,device_state
2026-01-23 13:00:00,2026-01-23 13:00:00.100,0.100,connect,VERSION,45,7,7,0.15,,COMPLETE,OTHER,0,IDLE
2026-01-23 13:00:00,2026-01-23 13:00:00.150,0.150,connect,CONNECT #1,25,5,12,0.20,,COMPLETE,ACK,0,IDLE
2026-01-23 13:00:00,2026-01-23 13:00:00.200,0.200,connect,HOME,145,5,17,0.03,,COMPLETE,ACK,0,IDLE
2026-01-23 13:00:00,2026-01-23 13:00:01.000,1.000,setup,FRAMING,20,5,22,0.25,,COMPLETE,ACK,0,IDLE
2026-01-23 13:00:00,2026-01-23 13:00:01.050,1.050,burn,DATA line 0,180,1904,1926,10.22,,COMPLETE,ACK,0,IDLE
2026-01-23 13:00:00,2026-01-23 13:00:02.000,2.000,wait,STATUS,0,0,1926,,15,COMPLETE,STATUS,0,BURNING
2026-01-23 13:00:00,2026-01-23 13:00:10.000,10.000,wait,STATUS,0,0,1926,,100,COMPLETE,STATUS,0,COMPLETE
,====

=== Testing

CSV logging is fully covered by unit tests. See `tests/test_csv_logging.py` for examples.


